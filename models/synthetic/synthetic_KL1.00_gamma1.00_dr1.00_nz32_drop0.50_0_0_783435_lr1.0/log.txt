Namespace(batch_size=32, cuda=False, dataset='synthetic', dec_dropout_in=0.5, dec_dropout_out=0.5, dec_nh=50, dec_type='lstm', decode_from='', decode_input='', decoding_strategy='greedy', delta_rate=1, device='cpu', enc_nh=50, enc_type='lstm', epochs=50, eval=False, gamma=1.0, iw_nsamples=500, jobid=0, kl_start=1.0, label=True, load_path='', log_path='models/synthetic/synthetic_KL1.00_gamma1.00_dr1.00_nz32_drop0.50_0_0_783435_lr1.0/log.txt', lr=1.0, momentum=0, ni=50, nsamples=1, nz=32, nz_new=32, p_drop=0.5, reset_dec=False, save_path='models/synthetic/synthetic_KL1.00_gamma1.00_dr1.00_nz32_drop0.50_0_0_783435_lr1.0/model.pt', seed=783435, target_kl=-1, taskid=0, test_data='data/synthetic_data/synthetic_test.txt', test_nepoch=1, train_data='data/synthetic_data/synthetic_train.txt', val_data='data/synthetic_data/synthetic_test.txt', vocab_file='data/synthetic_data/vocab.txt', warm_up=100)
data/synthetic_data/vocab.txt
Train data: 16000 samples
finish reading datasets, vocab size is 1004
dropped sentences: 0
epoch: 0, iter: 0, avg_loss: 109.8254, kl/H(z|x): 33.7955, mi: 0.0425, recon: 76.0299,au 0, time elapsed 3.76s
epoch: 0, iter: 50, avg_loss: 83.8892, kl/H(z|x): 16.9853, mi: -0.0774, recon: 66.9040,au 0, time elapsed 8.47s
epoch: 0, iter: 100, avg_loss: 75.9278, kl/H(z|x): 15.2441, mi: -0.0223, recon: 60.6837,au 0, time elapsed 13.28s
epoch: 0, iter: 150, avg_loss: 74.6431, kl/H(z|x): 15.2945, mi: 0.5371, recon: 59.3485,au 20, time elapsed 17.94s
epoch: 0, iter: 200, avg_loss: 72.5163, kl/H(z|x): 15.3962, mi: -0.0651, recon: 57.1201,au 0, time elapsed 22.74s
